{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNCjggC_JCLC"
   },
   "source": [
    "# **Customer Churn Prediction** ¶\n",
    "\n",
    "\n",
    "## **Problem Statement:**\n",
    "\n",
    "Develop a predictive model to identify customers at risk of churning from an investment bank, enabling proactive retention strategies to minimize customer loss and maximize revenue growth.\n",
    "\n",
    "\n",
    "## **About the Dataset**\n",
    "\n",
    "There are 14 columns/features and 10k rows/samples.\n",
    "\n",
    "**RowNumber**—corresponds to the record (row) number and has no effect on the output.\n",
    "\n",
    "**CustomerId**—contains random values and has no effect on customer leaving the bank.\n",
    "\n",
    "**Surname**—the surname of a customer has no impact on their decision to leave the bank.\n",
    "\n",
    "**CreditScore**—can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n",
    "\n",
    "**Geography**—a customer’s location can affect their decision to leave the bank.\n",
    "\n",
    "**Gender**—it’s interesting to explore whether gender plays a role in a customer leaving the bank.\n",
    "\n",
    "**Age**—this is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n",
    "\n",
    "**Tenure**—refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n",
    "\n",
    "**Balance**—also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.\n",
    "\n",
    "**NumOfProducts**—refers to the number of products that a customer has purchased through the bank.\n",
    "\n",
    "**HasCrCard**—denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n",
    "\n",
    "**IsActiveMember**—active customers are less likely to leave the bank.\n",
    "\n",
    "**EstimatedSalary**—as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n",
    "\n",
    "**Exited**—whether or not the customer left the bank.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsM-UZzFLU6K"
   },
   "source": [
    "## **KNN**\n",
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm is a simple and effective machine learning technique that classifies data points by finding the K most similar instances to a new input and voting for the target class or value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaiYMl810_bx"
   },
   "source": [
    "### **The most commonly used hyperparameters for K-Nearest Neighbors (KNN) algorithm:**\n",
    "\n",
    "n_neighbors: The number of nearest neighbors to consider when making a prediction. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "weights: The weight function used to calculate the distance between samples. Supported weights are 'uniform' (all points have equal weight) and 'distance' (points closer to the query point have higher weight).\n",
    "\n",
    "algorithm: The algorithm used to compute the nearest neighbors. Supported algorithms are 'brute' (exhaustive search), 'kd_tree' (k-d tree search), and 'ball_tree' (ball tree search).\n",
    "\n",
    "leaf_size: The number of samples in each leaf node of the k-d tree or ball tree. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "p: The power parameter for the Minkowski metric. When p=1, it is the Manhattan distance, and when p=2, it is the Euclidean distance.\n",
    "\n",
    "metric: The distance metric used to calculate the distance between samples. Supported metrics are 'minkowski' (Minkowski distance), 'euclidean' (Euclidean distance), 'manhattan' (Manhattan distance), and 'chebyshev' (Chebyshev distance).\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "n_neighbors: 3, 5, 10, 20\n",
    "\n",
    "weights: 'uniform', 'distance'\n",
    "\n",
    "algorithm: 'brute', 'kd_tree', 'ball_tree'\n",
    "\n",
    "leaf_size: 10, 20, 30\n",
    "\n",
    "p: 1, 2\n",
    "\n",
    "metric: 'minkowski', 'euclidean', 'manhattan', 'chebyshev'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VBDLDV06LVR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cM4BNUKTL1d1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-e6wApAqL1lZ"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qkO2K9I4L1r1",
    "outputId": "d95565df-2b88-4a50-8d89-87befe30f5cd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "data = pd.read_csv('Churn_data .csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "osdVP2q05m1v"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vabpuR-z5m4P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gXYD_VtT5m8M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is null?\n",
    "isnull = data.isnull().sum()\n",
    "isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n__3wDIp45E2"
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "selected_features = [\n",
    "    'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "    'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "    'IsActiveMember', 'EstimatedSalary'\n",
    "]\n",
    "X = data[selected_features]\n",
    "y = data[['Exited']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ibZA46O545HW"
   },
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "X['Geography'] = le.fit_transform(X['Geography'])\n",
    "X['Gender'] = le.fit_transform(X['Gender'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YXGEGbzC45Kr"
   },
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']] = scaler.fit_transform(X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j44gSfIV5Dc5"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    X, y, random_state=0, train_size=0.8\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UUKfmfYe5Di5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(leaf_size=50, metric=&#x27;euclidean&#x27;, n_neighbors=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(leaf_size=50, metric=&#x27;euclidean&#x27;, n_neighbors=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(leaf_size=50, metric='euclidean', n_neighbors=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model = KNeighborsClassifier(n_neighbors=2, metric='euclidean', weights='uniform', algorithm='auto', leaf_size=50, p=2)\n",
    "model.fit(train_X, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tS2Q1a0T45NM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.817\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "val_prediction = model.predict(val_X)\n",
    "y_pred_proba = model.predict_proba(val_X)[:,1]\n",
    "accuracy = accuracy_score(val_y, val_prediction)\n",
    "print(f'Model accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6g_36FlE5cIr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1535   60]\n",
      " [ 306   99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1595\n",
      "           1       0.62      0.24      0.35       405\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.73      0.60      0.62      2000\n",
      "weighted avg       0.79      0.82      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(val_y, val_prediction))\n",
    "print(classification_report(val_y, val_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PfUIhRrS-7zL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7075134486628739\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(val_y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcIiAzYb45Qi"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(model, 'churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mDoUgypvtYz"
   },
   "source": [
    "A Decision Tree Classifier is a type of supervised learning algorithm in machine learning. It works by creating a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. The tree is constructed by recursively partitioning the data into subsets based on the values of the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5KPCvs5v1YE"
   },
   "source": [
    "### **The most commonly used hyperparameters for Decision Tree Classifier**:\n",
    "\n",
    "criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "\n",
    "max_depth: The maximum depth of the tree. Increasing this number can improve the model's performance, but also increases the risk of overfitting.\n",
    "\n",
    "min_samples_split: The minimum number of samples required to split an internal node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "max_features: The maximum number of features to consider at each split. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "random_state: The random seed used to shuffle the data before splitting it into training and testing sets. Setting this to a fixed value ensures reproducibility of the results.\n",
    "\n",
    "class_weight: The weight assigned to each class during training. This can be useful for imbalanced datasets, where one class has a much larger number of instances than the others.\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "criterion: 'gini', 'entropy'\n",
    "\n",
    "max_depth: 3, 5, 10, None (None means no limit)\n",
    "\n",
    "min_samples_split: 2, 5, 10\n",
    "\n",
    "min_samples_leaf: 1, 5, 10\n",
    "\n",
    "max_features: 'auto', 'sqrt', 'log2', None (None means no limit)\n",
    "\n",
    "random_state: 0, 42, 100\n",
    "\n",
    "class_weight: 'balanced', 'balanced_subsample', None (None means all classes are equal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXMALsDkvTZ2"
   },
   "source": [
    "Random Forest is a supervised learning algorithm that combines multiple decision trees to produce a more accurate and stable prediction model. It works by creating a collection of decision trees, where each tree is trained on a random subset of the training data. The final prediction is made by combining the predictions of all the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULCkDZ9bvTl0"
   },
   "source": [
    "### **The most commonly used hyperparameters for Random Forest Classifier:**\n",
    "\n",
    "n_estimators: The number of trees in the forest. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "\n",
    "max_depth: The maximum depth of each tree. Increasing this number can improve the model's performance, but also increases the risk of overfitting.\n",
    "\n",
    "min_samples_split: The minimum number of samples required to split an internal node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "max_features: The maximum number of features to consider at each split. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "max_leaf_nodes: The maximum number of leaf nodes in each tree. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "min_impurity_decrease: The minimum decrease in impurity required to split an internal node. Increasing this number can lead to underfitting, while decreasing it can lead to overfitting.\n",
    "\n",
    "bootstrap: Whether to use bootstrap sampling to build each tree. If True, each tree is built on a random subset of the training data.\n",
    "\n",
    "oob_score: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
    "\n",
    "random_state: The random seed used to shuffle the data before building each tree. Setting this to a fixed value ensures reproducibility of the results.\n",
    "\n",
    "class_weight: The weight assigned to each class during training. This can be useful for imbalanced datasets, where one class has a much larger number of instances than the others.\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "n_estimators: 10, 50, 100, 200\n",
    "\n",
    "criterion: 'gini', 'entropy'\n",
    "\n",
    "max_depth: 3, 5, 10, None (None means no limit)\n",
    "\n",
    "min_samples_split: 2, 5, 10\n",
    "\n",
    "min_samples_leaf: 1, 5, 10\n",
    "\n",
    "max_features: 'auto', 'sqrt', 'log2', None (None means no limit)\n",
    "\n",
    "max_leaf_nodes: 10, 50, 100, None (None means no limit)\n",
    "\n",
    "min_impurity_decrease: 0.0, 0.1, 0.5\n",
    "\n",
    "bootstrap: True, False\n",
    "\n",
    "oob_score: True, False\n",
    "\n",
    "random_state: 0, 42, 100\n",
    "\n",
    "class_weight: 'balanced', 'balanced_subsample', None (None means all classes are equal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt3QA9hZxhuL"
   },
   "source": [
    "Support Vector Machine (SVM) is a supervised learning algorithm that can be used for classification and regression tasks. It works by finding the hyperplane that maximally separates the classes in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ui_ycx2xiJA"
   },
   "source": [
    "### **The most commonly used hyperparameters for Support Vector Machines (SVMs) are:**\n",
    "\n",
    "C: The regularization parameter. It controls the trade-off between the margin and the misclassification error.\n",
    "\n",
    "\n",
    "kernel: The kernel function used to transform the data into a higher dimensional space.\n",
    "\n",
    "\n",
    "gamma: The kernel coefficient. It is used to control the spread of the kernel.\n",
    "degree: The degree of the polynomial kernel.\n",
    "\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "C: 1.0, 10.0, 100.0, 1000.0\n",
    "\n",
    "kernel: 'rbf', 'linear', 'poly', 'sigmoid'\n",
    "\n",
    "gamma: 'scale', 'auto', 0.1, 1.0, 10.0\n",
    "\n",
    "degree: 2, 3, 4, 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRVNWzbwOTrH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huPNIDUVOTyK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg4EATyrOT3i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
